<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>machine-learning on Girish Varma</title>
    <link>https://girishvarma.in/projects/machine-learning/</link>
    <description>Recent content in machine-learning on Girish Varma</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 01 Aug 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://girishvarma.in/projects/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Automated Seed Quality Testing System using GAN &amp; Active Learning</title>
      <link>https://girishvarma.in/publication/seed/</link>
      <pubDate>Sun, 01 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/seed/</guid>
      <description>Quality assessment of agricultural produce is a crucial step in minimizing food stock wastage. However, this is currently done manually and often requires expert supervision, especially in smaller seeds like corn. We propose a novel computer vision-based system for automating this process. We build a novel seed image acquisition setup, which captures both the top and bottom views. Dataset collection for this problem has challenges of data annotation costs/time and class imbalance.</description>
    </item>
    
    <item>
      <title>CInC Flow: Characterizable Invertible 3x3 Convolution</title>
      <link>https://girishvarma.in/publication/cinc-flow/</link>
      <pubDate>Mon, 07 Jun 2021 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/cinc-flow/</guid>
      <description>Normalizing flows are an essential alternative to GANs for generative modelling, which can be optimized directly on the maximum likelihood of the dataset. They also allow computation of the exact latent vector corresponding to an image since they are composed of invertible transformations. However, the requirement of invertibility of the transformation prevents standard and expressive neural network models such as CNNs from being directly used. Emergent convolutions were proposed to construct an invertible 3x3 CNN layer using a pair of masked CNN layers, making them inefficient.</description>
    </item>
    
    <item>
      <title>Ramanujan Bipartite Graph Products for Efficient Block Sparse Neural Networks</title>
      <link>https://girishvarma.in/publication/rbgp/</link>
      <pubDate>Thu, 01 Apr 2021 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/rbgp/</guid>
      <description>Sparse neural networks are shown to give accurate predictions competitive to denser versions, while also minimizing the number of arithmetic operations performed. However current GPU hardware can only exploit structured sparsity patterns for better efficiency. We propose a framework for generating structured multi-level block sparse neural networks by using the theory of graph products. Our Ramanujan Bipartite Graph Product (RBGP) framework uses products of Ramanujan graphs to obtain the best connectivity for a given level of sparsity.</description>
    </item>
    
    <item>
      <title>Markov Chain Monte Carlo: Theory, Applications and Interdisciplinary Problems</title>
      <link>https://girishvarma.in/teaching/mcmc/</link>
      <pubDate>Fri, 01 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/teaching/mcmc/</guid>
      <description>A project oriented course on theory and applications of MCMC techniques.</description>
    </item>
    
    <item>
      <title>Deep Learning Enabled Inorganic Material Generator</title>
      <link>https://girishvarma.in/publication/ding/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/ding/</guid>
      <description>Recent years have witnessed utilization of modern machine learning approaches for predicting properties of material using available datasets. However, to identify potential candidates for material discovery, one has to systematically scan through a large chemical space and subsequently calculate the properties of all such samples. On the other hand, generative methods are capable of efficiently sampling the chemical space and can generate molecules/materials with desired properties. In this study, we report a deep learning based inorganic material generator (DING) framework consisting of a generator module and a predictor module.</description>
    </item>
    
    <item>
      <title>Using Artificial Intelligence (AI) to Classify Retinal Developmental Disorders</title>
      <link>https://girishvarma.in/publication/dlfovea/</link>
      <pubDate>Fri, 01 May 2020 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/dlfovea/</guid>
      <description>Purpose : Artificial intelligence (AI) is particularly effective in image recognition as demonstrated in radiology, pathology and recently ophthalmology. Foveal hypoplasia (FH) is a group of disorders characterised by arrested retinal development and often associated with infantile nystagmus. Identifying the degree of arrested retinal development using optical coherence tomography (OCT) is paramount as this information provides both diagnostic and prognostic value. To date, there are no AI systems available for paediatric OCT or childhood nystagmus.</description>
    </item>
    
    <item>
      <title></title>
      <link>https://girishvarma.in/students/aditya-kallapa/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/students/aditya-kallapa/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://girishvarma.in/students/furqan-sheik/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/students/furqan-sheik/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://girishvarma.in/students/garima-nishad/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/students/garima-nishad/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://girishvarma.in/students/prateek-pani/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/students/prateek-pani/</guid>
      <description></description>
    </item>
    
    <item>
      <title></title>
      <link>https://girishvarma.in/students/sandeep-kumar/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/students/sandeep-kumar/</guid>
      <description></description>
    </item>
    
    <item>
      <title>Probabilistic Graphical Models</title>
      <link>https://girishvarma.in/teaching/prob-graph-models/</link>
      <pubDate>Thu, 02 Jan 2020 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/teaching/prob-graph-models/</guid>
      <description>Probabilistic Graphical Models refers to  i.) concise representations of probability distributions using graphs ii.) efficient algorithms for sampling distributions represented in such form iii.) learning these representations from data.</description>
    </item>
    
    <item>
      <title>Semantic Segmentation Datasets for Resource Constrained Training</title>
      <link>https://girishvarma.in/publication/idd-lite/</link>
      <pubDate>Tue, 22 Oct 2019 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/idd-lite/</guid>
      <description>Several large scale datasets, coupled with advances in deep neural network architectures have been greatly successful in pushing the boundaries of performance in semantic segmentation in recent years. However, the scale and magnitude of such datasets prohibits ubiquitous use and widespread adoption of such models, especially in settings with serious hardware and software resource constraints. Through this work, we propose two simple variants of the recently proposed IDD dataset, namely IDD-mini and IDD-lite, for scene understanding in unstructured environments.</description>
    </item>
    
    <item>
      <title>Dynamic Block Sparse Reparametarization of Convolutional Neural Networks</title>
      <link>https://girishvarma.in/publication/block-sparse/</link>
      <pubDate>Tue, 27 Aug 2019 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/block-sparse/</guid>
      <description>Sparse neural networks are efficient in both memory and compute when compared to dense neural networks. But on parallel hardware such as GPU, sparse neural networks result in small or no runtime performance gains. On the other hand, structured sparsity patterns like filter, channel and block sparsity result in large performance gains due to regularity induced by structure. Among structured sparsities, block sparsity is a generic structured sparsity pattern with filter and channel sparsity being sub cases of block sparsity.</description>
    </item>
    
    <item>
      <title>Machine Learning in Natural Sciences</title>
      <link>https://girishvarma.in/teaching/ml4science/</link>
      <pubDate>Tue, 01 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/teaching/ml4science/</guid>
      <description>A project oriented course in applying machine learning techniques to solving problems in natural sciences.</description>
    </item>
    
    <item>
      <title>Universal Semi-supervised Semantic Segmentation</title>
      <link>https://girishvarma.in/publication/univ-seg/</link>
      <pubDate>Fri, 16 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/univ-seg/</guid>
      <description>In recent years, the need for semantic segmentation has arisen across several different applications and environments. However, the expense and redundancy of annotation often limits the quantity of labels available for training in any domain, while deployment is easier if a single model works well across domains. In this paper, we pose the novel problem of universal semi-supervised semantic segmentation and propose a solution framework, to meet the dual needs of lower annotation and deployment costs.</description>
    </item>
    
    <item>
      <title>Class2Str: End to End Latent Hierarchy Learning</title>
      <link>https://girishvarma.in/publication/class2str/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/publication/class2str/</guid>
      <description>Deep neural networks for image classification typically consists of a convolutional feature extractor followed by a fully connected classifier network. The predicted and the ground truth labels are represented as one hot vectors. Such a representation assumes that all classes are equally dissimilar. However, classes have visual similarities and often form a hierarchy. Learning this latent hierarchy explicitly in the architecture could provide invaluable insights. We propose an alternate architecture to the classifier network called the Latent Hierarchy (LH) Classifier and an end to end learned Class2Str mapping which discovers a latent hierarchy of the classes.</description>
    </item>
    
    <item>
      <title>Efficient CNNs</title>
      <link>https://girishvarma.in/teaching/efficient-cnns/</link>
      <pubDate>Mon, 01 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://girishvarma.in/teaching/efficient-cnns/</guid>
      <description>Surveying methods used to make deep learning models efficient.</description>
    </item>
    
  </channel>
</rss>
